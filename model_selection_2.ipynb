{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned emotion data\n",
    "df_emosi = pd.read_csv(r'src/cleaned_emotion_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emosi.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and labels\n",
    "X = df_emosi['tweet']\n",
    "y = df_emosi['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature extraction methods\n",
    "vectorizers = {\n",
    "    'bow': CountVectorizer(),\n",
    "    'tfidf': TfidfVectorizer(),\n",
    "    'ngram': CountVectorizer(ngram_range=(1, 2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifiers\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate the models with combinations of features\n",
    "def evaluate_model(name, model, vectorizer_combinations):\n",
    "    for vectorizer_names in vectorizer_combinations:\n",
    "        features = [vectorizers[name] for name in vectorizer_names]\n",
    "        combined_features = FeatureUnion([(name, vectorizer) for name, vectorizer in zip(vectorizer_names, features)])\n",
    "        pipeline = Pipeline([\n",
    "            (\"features\", combined_features),\n",
    "            (\"classifier\", model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Features': '+'.join(vectorizer_names),\n",
    "            'Accuracy': report['accuracy'],\n",
    "            'Precision': report['macro avg']['precision'],\n",
    "            'Recall': report['macro avg']['recall'],\n",
    "            'F1-Score': report['macro avg']['f1-score']\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models with different feature combinations\n",
    "for model_name, model in models.items():\n",
    "    for r in range(1, len(vectorizers) + 1):\n",
    "        for vectorizer_combinations in combinations(vectorizers.keys(), r):\n",
    "            evaluate_model(model_name, model, [vectorizer_combinations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Features</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.730932</td>\n",
       "      <td>0.744781</td>\n",
       "      <td>0.738857</td>\n",
       "      <td>0.738726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bow+tfidf</td>\n",
       "      <td>0.721045</td>\n",
       "      <td>0.729570</td>\n",
       "      <td>0.737514</td>\n",
       "      <td>0.729730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>tfidf+ngram</td>\n",
       "      <td>0.719633</td>\n",
       "      <td>0.734323</td>\n",
       "      <td>0.729049</td>\n",
       "      <td>0.727664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>tfidf+ngram</td>\n",
       "      <td>0.716808</td>\n",
       "      <td>0.732096</td>\n",
       "      <td>0.727495</td>\n",
       "      <td>0.726025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bow+tfidf+ngram</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.727438</td>\n",
       "      <td>0.733696</td>\n",
       "      <td>0.725697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>bow+tfidf+ngram</td>\n",
       "      <td>0.714689</td>\n",
       "      <td>0.731998</td>\n",
       "      <td>0.724362</td>\n",
       "      <td>0.724653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>ngram</td>\n",
       "      <td>0.713983</td>\n",
       "      <td>0.730136</td>\n",
       "      <td>0.725553</td>\n",
       "      <td>0.724053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>bow+ngram</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.729606</td>\n",
       "      <td>0.721940</td>\n",
       "      <td>0.722193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.713983</td>\n",
       "      <td>0.743755</td>\n",
       "      <td>0.712341</td>\n",
       "      <td>0.721433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM</td>\n",
       "      <td>bow+tfidf</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.735829</td>\n",
       "      <td>0.712238</td>\n",
       "      <td>0.719273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.731094</td>\n",
       "      <td>0.704083</td>\n",
       "      <td>0.712807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.702684</td>\n",
       "      <td>0.713184</td>\n",
       "      <td>0.718729</td>\n",
       "      <td>0.712599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>ngram</td>\n",
       "      <td>0.701977</td>\n",
       "      <td>0.714500</td>\n",
       "      <td>0.711279</td>\n",
       "      <td>0.710328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bow+ngram</td>\n",
       "      <td>0.697740</td>\n",
       "      <td>0.710413</td>\n",
       "      <td>0.710978</td>\n",
       "      <td>0.707337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>bow+tfidf+ngram</td>\n",
       "      <td>0.663842</td>\n",
       "      <td>0.730494</td>\n",
       "      <td>0.645233</td>\n",
       "      <td>0.669847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>bow+ngram</td>\n",
       "      <td>0.660311</td>\n",
       "      <td>0.728156</td>\n",
       "      <td>0.642507</td>\n",
       "      <td>0.666131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>ngram</td>\n",
       "      <td>0.658898</td>\n",
       "      <td>0.740507</td>\n",
       "      <td>0.635022</td>\n",
       "      <td>0.663209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>tfidf+ngram</td>\n",
       "      <td>0.656780</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>0.632090</td>\n",
       "      <td>0.661642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.653955</td>\n",
       "      <td>0.701634</td>\n",
       "      <td>0.641239</td>\n",
       "      <td>0.658745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>bow+tfidf</td>\n",
       "      <td>0.644774</td>\n",
       "      <td>0.718421</td>\n",
       "      <td>0.622457</td>\n",
       "      <td>0.649948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.512006</td>\n",
       "      <td>0.797363</td>\n",
       "      <td>0.433168</td>\n",
       "      <td>0.476154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model         Features  Accuracy  Precision    Recall  F1-Score\n",
       "0   Random Forest            tfidf  0.730932   0.744781  0.738857  0.738726\n",
       "1   Random Forest        bow+tfidf  0.721045   0.729570  0.737514  0.729730\n",
       "2   Random Forest      tfidf+ngram  0.719633   0.734323  0.729049  0.727664\n",
       "3             SVM      tfidf+ngram  0.716808   0.732096  0.727495  0.726025\n",
       "4   Random Forest  bow+tfidf+ngram  0.717514   0.727438  0.733696  0.725697\n",
       "5             SVM  bow+tfidf+ngram  0.714689   0.731998  0.724362  0.724653\n",
       "6             SVM            ngram  0.713983   0.730136  0.725553  0.724053\n",
       "7             SVM        bow+ngram  0.711864   0.729606  0.721940  0.722193\n",
       "8             SVM            tfidf  0.713983   0.743755  0.712341  0.721433\n",
       "9             SVM        bow+tfidf  0.708333   0.735829  0.712238  0.719273\n",
       "10            SVM              bow  0.700565   0.731094  0.704083  0.712807\n",
       "11  Random Forest              bow  0.702684   0.713184  0.718729  0.712599\n",
       "12  Random Forest            ngram  0.701977   0.714500  0.711279  0.710328\n",
       "13  Random Forest        bow+ngram  0.697740   0.710413  0.710978  0.707337\n",
       "14    Naive Bayes  bow+tfidf+ngram  0.663842   0.730494  0.645233  0.669847\n",
       "15    Naive Bayes        bow+ngram  0.660311   0.728156  0.642507  0.666131\n",
       "16    Naive Bayes            ngram  0.658898   0.740507  0.635022  0.663209\n",
       "17    Naive Bayes      tfidf+ngram  0.656780   0.738002  0.632090  0.661642\n",
       "18    Naive Bayes              bow  0.653955   0.701634  0.641239  0.658745\n",
       "19    Naive Bayes        bow+tfidf  0.644774   0.718421  0.622457  0.649948\n",
       "20    Naive Bayes            tfidf  0.512006   0.797363  0.433168  0.476154"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results\n",
    "results_df.sort_values(by='F1-Score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c69f9e4fcdd4b65bf345debe5a64d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6998763469351705\n",
      "Best Parameters: {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__n_estimators': 100}\n",
      "RandomForestClassifier with Combined Features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.72      0.74      0.73       233\n",
      "        Fear       0.78      0.82      0.80       198\n",
      "         Joy       0.79      0.69      0.74       240\n",
      "        Love       0.66      0.86      0.75       161\n",
      "     Neutral       0.68      0.65      0.67       394\n",
      "         Sad       0.75      0.67      0.71       190\n",
      "\n",
      "    accuracy                           0.72      1416\n",
      "   macro avg       0.73      0.74      0.73      1416\n",
      "weighted avg       0.73      0.72      0.72      1416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_score\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "# Define the feature extraction steps\n",
    "vectorizer_bow = CountVectorizer()\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "\n",
    "# Combine the features using FeatureUnion\n",
    "combined_features = FeatureUnion([\n",
    "    (\"bow\", vectorizer_bow),\n",
    "    (\"tfidf\", vectorizer_tfidf)\n",
    "])\n",
    "\n",
    "# Create a pipeline that first transforms the data and then applies the model\n",
    "pipeline = Pipeline([\n",
    "    (\"features\", combined_features),\n",
    "    (\"clf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "     \"clf__n_estimators\": [100, 200, 500],\n",
    "    \"clf__max_depth\": [None, 10, 20],\n",
    "    \"clf__max_features\": ['sqrt', 'log2', 0.2, 0.5, 0.8],\n",
    "    # \"clf__min_samples_split\": [2, 5, 10],\n",
    "    # \"clf__min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create parameter grid\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "# Create the progress bar\n",
    "progress_bar = tqdm(total=len(param_grid))\n",
    "\n",
    "# Variable to keep track of the best score and best parameters\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "# Manually iterate over the parameter grid\n",
    "for params in param_grid:\n",
    "    pipeline.set_params(**params)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        scores = cross_val_score(pipeline, X_train, y_train, cv=3, n_jobs=-1)\n",
    "    score = np.mean(scores)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "print(f\"Best Score: {best_score}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Set the best parameters and train the final model\n",
    "pipeline.set_params(**best_params)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"RandomForestClassifier with Combined Features\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
