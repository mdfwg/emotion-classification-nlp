{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ebUIan1kWjuC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cbpZout6E5rg"
      },
      "outputs": [],
      "source": [
        "df_emosi=pd.read_csv(r'src\\emotion_2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baIkTC_gIQlP"
      },
      "source": [
        "### Missval Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GebdnPDcIU5x",
        "outputId": "9ec5fb91-0d22-4fe0-d953-a275b41ba2c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Tweet    0\n",
              "Label    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_emosi.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rename columns Tweet to tweet and Label to label\n",
        "df_emosi.rename(columns={'Tweet':'tweet','Label':'label'},inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDvF724DmrDi"
      },
      "source": [
        "### Slang dan Abreviasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bJew3ZD2fsVP"
      },
      "outputs": [],
      "source": [
        "kamus_slang=pd.read_csv(r'src\\colloquial-indonesian-lexicon.csv')\n",
        "kamus_slang=kamus_slang.rename(columns = {'slang' : 'kamus_slang' , 'formal' : 'kamus_perbaikan'})\n",
        "\n",
        "# Rekonstruksi data sebagai 'dict'\n",
        "slang_mapping = dict(zip(kamus_slang['kamus_slang'], kamus_slang['kamus_perbaikan']))\n",
        "kamus_singkatan = pd.read_csv(r'src\\kamus_singkatan.csv', header=None, names=['sebelum_perbaikan', 'setelah_perbaikan'],delimiter=';')\n",
        "singkatan_mapping=dict(zip(kamus_singkatan['sebelum_perbaikan'],kamus_singkatan['setelah_perbaikan']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkUcqaK5myg9"
      },
      "source": [
        "### Stopword, emoji, dan Stemmer Factory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9KdjU3vdiG8J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in c:\\users\\user\\anaconda3\\lib\\site-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.24.4)\n",
            "Requirement already satisfied: language-data>=1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import  StopWordRemoverFactory\n",
        "import emoji\n",
        "from spacy.lang.id import Indonesian\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yMqvORsOh_bN"
      },
      "outputs": [],
      "source": [
        "stopword_factory = StopWordRemoverFactory()\n",
        "stopwords = stopword_factory.get_stop_words()\n",
        "# List of words with negation meaning\n",
        "emoji_data = emoji.EMOJI_DATA\n",
        "\n",
        "# Remove negation words from stopwords\n",
        "# stopwords = set(stopwords).difference(excluded_stopwords)\n",
        "nlp = Indonesian()\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yHYIcUulqlkd"
      },
      "outputs": [],
      "source": [
        "def replace_emoji_with_ascii(text, emoji_data, language='id'):\n",
        "    for emoji, translations in emoji_data.items():\n",
        "        if language in translations:\n",
        "            text = text.replace(emoji, translations[language])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htCsjSPpxcbq",
        "outputId": "45abd325-3495-44de-d8df-f57272722bf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saat kamu merenungkan tentang kehilangan yang pernah kamu alami, lukarusluka itu terasa kembali dalam ingatan. patahmaskhati mekar #RememberingLoss\n"
          ]
        }
      ],
      "source": [
        "text_with_emoji = \"Saat kamu merenungkan tentang kehilangan yang pernah kamu alami, luka-luka itu terasa kembali dalam ingatan. ðŸ’”ðŸŒ¼ #RememberingLoss\"\n",
        "a = replace_emoji_with_ascii(text_with_emoji, emoji_data, language='id')\n",
        "a = a.replace(\":\",' ').replace('_','mask').replace('-','rus').strip()\n",
        "a = re.sub(' +', ' ', a)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "A_fwSAIGlHjR"
      },
      "outputs": [],
      "source": [
        "def process_tweet(tweet) :\n",
        "  tweet=tweet.lower()\n",
        "  # link\n",
        "  tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet)\n",
        "\n",
        "  # spesifik\n",
        "  # tweet = re.sub(r'\\[username\\]|\\[url\\]|\\[askmf\\]|\\[sensitive-no\\]|\\[satu menit kemudian\\]|\\[c48\\]|\\[idm\\]', '', tweet)\n",
        "\n",
        "  # emoji\n",
        "  # tweet=replace_emoji_with_ascii(tweet,emoji_data)\n",
        "  # tweet=tweet.replace(\":\",' ').replace('_','mask').replace('-','rus').strip()\n",
        "  # tweet=re.sub(' +', ' ', tweet)\n",
        "\n",
        "  # tokenisasi\n",
        "  tokens = tweet.split()\n",
        "\n",
        "  tweet_tokens = []\n",
        "  for ele in tokens:\n",
        "    ele_kamus = kamus_singkatan.get(ele, ele)\n",
        "    ele_slang = slang_mapping.get(ele_kamus, ele_kamus)\n",
        "    tweet_tokens.append(ele_slang)\n",
        "\n",
        "  tweet = ' '.join(tweet_tokens)\n",
        "  tweet = re.sub('[\\s]+', ' ', tweet)\n",
        "    #Replace #word with word\n",
        "  # tweet = re.sub(r'#([^\\s]+)', '', tweet)\n",
        "  tweet=re.sub(r'\\d+', '', tweet)\n",
        "  tweet = tweet.strip('\\'\"')\n",
        "  tweet = tweet.lstrip('\\'\"')\n",
        "\n",
        "  tweet = \"\".join([char for char in tweet if char not in string.punctuation])\n",
        "\n",
        "  doc = nlp(tweet)\n",
        "\n",
        "  tokens = [token.text for token in doc]\n",
        "      # Hapus stopwords dari tokens\n",
        "  filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
        "  tweet = ' '.join(filtered_tokens)\n",
        "\n",
        "  tweet=stemmer.stem(tweet)\n",
        "  # tweet=tweet.replace('mask',' ').replace('rus','-')\n",
        "\n",
        "  return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tQAIMjZJNnP",
        "outputId": "d2c232dd-2ed7-4580-e074-f19c2a30029a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hai sayang\n"
          ]
        }
      ],
      "source": [
        "print(process_tweet('hai sayangnya adalah ðŸ˜‚'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIJ3Ngn6Ip-y",
        "outputId": "ca386777-c271-45fd-fd2b-fc2ef166c137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pagi buat emosi\n"
          ]
        }
      ],
      "source": [
        "print(process_tweet(str(df_emosi['tweet'][0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qWWlAFV6omNo",
        "outputId": "5fe165f1-0e67-44ab-85e1-83fd1e8df4b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pagi2 udah di buat emosi :)</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kok stabilitas negara, memange 10 thn negara t...</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dah lah emosi mulu liat emyu</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aib? bodoh benar! sebelum kata aib itu muncul,...</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dih lu yg nyebelin bego</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  label\n",
              "0                        pagi2 udah di buat emosi :)  Anger\n",
              "1  kok stabilitas negara, memange 10 thn negara t...  Anger\n",
              "2                       dah lah emosi mulu liat emyu  Anger\n",
              "3  aib? bodoh benar! sebelum kata aib itu muncul,...  Anger\n",
              "4                            dih lu yg nyebelin bego  Anger"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_emosi.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rXqpk-wRo2TZ"
      },
      "outputs": [],
      "source": [
        "df_emosi['tweet'] = df_emosi['tweet'].apply(lambda x: process_tweet(str(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Lzg2VV3WrNAX"
      },
      "outputs": [],
      "source": [
        "df_emosi.to_csv(r'src\\cleaned_emotion_2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "E7CxM3omsCsG"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pagi buat emosi</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kok stabilitas negara memange tahun negara ama...</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>deh lah emosi mulu lihat emyu</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aib bodoh benar kata aib muncul lebih tindak k...</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dih lu sebal bego</td>\n",
              "      <td>Anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7075</th>\n",
              "      <td>pagi isi semesta sujud zat acap lupa kau sebut...</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7076</th>\n",
              "      <td>meski engkau pergi meski engkau tinggal meski ...</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7077</th>\n",
              "      <td>biasa kalah sakit</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7078</th>\n",
              "      <td>apakabar ku baikbaik aku sedang baik fikiranku...</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7079</th>\n",
              "      <td>this user sedang tidakbaikbaik sedang stres</td>\n",
              "      <td>Sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7080 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweet  label\n",
              "0                                       pagi buat emosi  Anger\n",
              "1     kok stabilitas negara memange tahun negara ama...  Anger\n",
              "2                         deh lah emosi mulu lihat emyu  Anger\n",
              "3     aib bodoh benar kata aib muncul lebih tindak k...  Anger\n",
              "4                                     dih lu sebal bego  Anger\n",
              "...                                                 ...    ...\n",
              "7075  pagi isi semesta sujud zat acap lupa kau sebut...    Sad\n",
              "7076  meski engkau pergi meski engkau tinggal meski ...    Sad\n",
              "7077                                  biasa kalah sakit    Sad\n",
              "7078  apakabar ku baikbaik aku sedang baik fikiranku...    Sad\n",
              "7079        this user sedang tidakbaikbaik sedang stres    Sad\n",
              "\n",
              "[7080 rows x 2 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_emosi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qKN9IBvcoReY",
        "1ip-ys6uoaY0"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
