{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned emotion data\n",
    "df_emosi = pd.read_csv(r'src/cleaned_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and labels\n",
    "X = df_emosi['tweet']\n",
    "y = df_emosi['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature extraction methods\n",
    "vectorizers = {\n",
    "    'bow': CountVectorizer(),\n",
    "    'tfidf': TfidfVectorizer(),\n",
    "    'ngram': CountVectorizer(ngram_range=(1, 2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifiers\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate the models with combinations of features\n",
    "def evaluate_model(name, model, vectorizer_combinations):\n",
    "    for vectorizer_names in vectorizer_combinations:\n",
    "        features = [vectorizers[name] for name in vectorizer_names]\n",
    "        combined_features = FeatureUnion([(name, vectorizer) for name, vectorizer in zip(vectorizer_names, features)])\n",
    "        pipeline = Pipeline([\n",
    "            (\"features\", combined_features),\n",
    "            (\"classifier\", model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Features': '+'.join(vectorizer_names),\n",
    "            'Accuracy': report['accuracy'],\n",
    "            'Precision': report['macro avg']['precision'],\n",
    "            'Recall': report['macro avg']['recall'],\n",
    "            'F1-Score': report['macro avg']['f1-score']\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models with different feature combinations\n",
    "for model_name, model in models.items():\n",
    "    for r in range(1, len(vectorizers) + 1):\n",
    "        for vectorizer_combinations in combinations(vectorizers.keys(), r):\n",
    "            evaluate_model(model_name, model, [vectorizer_combinations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Features</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>ngram</td>\n",
       "      <td>0.674234</td>\n",
       "      <td>0.703830</td>\n",
       "      <td>0.667995</td>\n",
       "      <td>0.680426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>bow+tfidf</td>\n",
       "      <td>0.675369</td>\n",
       "      <td>0.700821</td>\n",
       "      <td>0.668567</td>\n",
       "      <td>0.679687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>bow+ngram</td>\n",
       "      <td>0.673099</td>\n",
       "      <td>0.698683</td>\n",
       "      <td>0.668910</td>\n",
       "      <td>0.679439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>tfidf+ngram</td>\n",
       "      <td>0.671964</td>\n",
       "      <td>0.703486</td>\n",
       "      <td>0.665310</td>\n",
       "      <td>0.678579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.673099</td>\n",
       "      <td>0.684548</td>\n",
       "      <td>0.672454</td>\n",
       "      <td>0.676479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>bow+tfidf+ngram</td>\n",
       "      <td>0.670829</td>\n",
       "      <td>0.697043</td>\n",
       "      <td>0.664868</td>\n",
       "      <td>0.675957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.652667</td>\n",
       "      <td>0.696266</td>\n",
       "      <td>0.643091</td>\n",
       "      <td>0.658787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bow+tfidf</td>\n",
       "      <td>0.629966</td>\n",
       "      <td>0.670739</td>\n",
       "      <td>0.641313</td>\n",
       "      <td>0.645127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>tfidf+ngram</td>\n",
       "      <td>0.625426</td>\n",
       "      <td>0.666431</td>\n",
       "      <td>0.637684</td>\n",
       "      <td>0.638388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>ngram</td>\n",
       "      <td>0.627696</td>\n",
       "      <td>0.677261</td>\n",
       "      <td>0.636306</td>\n",
       "      <td>0.637349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.619750</td>\n",
       "      <td>0.663964</td>\n",
       "      <td>0.614812</td>\n",
       "      <td>0.626992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bow+tfidf+ngram</td>\n",
       "      <td>0.614075</td>\n",
       "      <td>0.660308</td>\n",
       "      <td>0.623970</td>\n",
       "      <td>0.626385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVM</td>\n",
       "      <td>bow+tfidf</td>\n",
       "      <td>0.618615</td>\n",
       "      <td>0.663008</td>\n",
       "      <td>0.613812</td>\n",
       "      <td>0.625879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bow</td>\n",
       "      <td>0.611805</td>\n",
       "      <td>0.653796</td>\n",
       "      <td>0.626164</td>\n",
       "      <td>0.625648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.610670</td>\n",
       "      <td>0.653262</td>\n",
       "      <td>0.626446</td>\n",
       "      <td>0.624668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bow+ngram</td>\n",
       "      <td>0.615210</td>\n",
       "      <td>0.662044</td>\n",
       "      <td>0.623848</td>\n",
       "      <td>0.624573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM</td>\n",
       "      <td>tfidf+ngram</td>\n",
       "      <td>0.614075</td>\n",
       "      <td>0.654492</td>\n",
       "      <td>0.611061</td>\n",
       "      <td>0.620521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>ngram</td>\n",
       "      <td>0.614075</td>\n",
       "      <td>0.654265</td>\n",
       "      <td>0.611061</td>\n",
       "      <td>0.620474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVM</td>\n",
       "      <td>bow+tfidf+ngram</td>\n",
       "      <td>0.611805</td>\n",
       "      <td>0.654485</td>\n",
       "      <td>0.609126</td>\n",
       "      <td>0.619489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVM</td>\n",
       "      <td>bow+ngram</td>\n",
       "      <td>0.610670</td>\n",
       "      <td>0.653563</td>\n",
       "      <td>0.608191</td>\n",
       "      <td>0.618614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.608400</td>\n",
       "      <td>0.722336</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>0.578067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model         Features  Accuracy  Precision    Recall  F1-Score\n",
       "0     Naive Bayes            ngram  0.674234   0.703830  0.667995  0.680426\n",
       "1     Naive Bayes        bow+tfidf  0.675369   0.700821  0.668567  0.679687\n",
       "2     Naive Bayes        bow+ngram  0.673099   0.698683  0.668910  0.679439\n",
       "3     Naive Bayes      tfidf+ngram  0.671964   0.703486  0.665310  0.678579\n",
       "4     Naive Bayes              bow  0.673099   0.684548  0.672454  0.676479\n",
       "5     Naive Bayes  bow+tfidf+ngram  0.670829   0.697043  0.664868  0.675957\n",
       "6             SVM            tfidf  0.652667   0.696266  0.643091  0.658787\n",
       "7   Random Forest        bow+tfidf  0.629966   0.670739  0.641313  0.645127\n",
       "8   Random Forest      tfidf+ngram  0.625426   0.666431  0.637684  0.638388\n",
       "9   Random Forest            ngram  0.627696   0.677261  0.636306  0.637349\n",
       "10            SVM              bow  0.619750   0.663964  0.614812  0.626992\n",
       "11  Random Forest  bow+tfidf+ngram  0.614075   0.660308  0.623970  0.626385\n",
       "12            SVM        bow+tfidf  0.618615   0.663008  0.613812  0.625879\n",
       "13  Random Forest              bow  0.611805   0.653796  0.626164  0.625648\n",
       "14  Random Forest            tfidf  0.610670   0.653262  0.626446  0.624668\n",
       "15  Random Forest        bow+ngram  0.615210   0.662044  0.623848  0.624573\n",
       "16            SVM      tfidf+ngram  0.614075   0.654492  0.611061  0.620521\n",
       "17            SVM            ngram  0.614075   0.654265  0.611061  0.620474\n",
       "18            SVM  bow+tfidf+ngram  0.611805   0.654485  0.609126  0.619489\n",
       "19            SVM        bow+ngram  0.610670   0.653563  0.608191  0.618614\n",
       "20    Naive Bayes            tfidf  0.608400   0.722336  0.558800  0.578067"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the results\n",
    "results_df.sort_values(by='F1-Score', ascending=False).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
