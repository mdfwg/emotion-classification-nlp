{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use each representation separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emosi = pd.read_csv(r'src\\emotion_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df_emosi['tweet']\n",
    "y = df_emosi['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1769    kaget berita tetangga satu rt solo tahun tingg...\n",
       "1220          tidak-enak sangat bada pulang kerjan banyak\n",
       "44      iya ibu nya lahir anak cewek enggak tahu tahun...\n",
       "289     jiyeeee jiyeee jeng dom habis menang lawan kei...\n",
       "2486    cinta penuh banyak buat semua harga tak satu l...\n",
       "                              ...                        \n",
       "3444    sahabat perlu filosopi milik nilai hidup beri ...\n",
       "466     banyak bilang pilih sopir mobil bener bawa mas...\n",
       "3092    bilang tetap pegang janji nikah brhak hakim su...\n",
       "3772    allahapa kok disalahin pres kayak presiden kur...\n",
       "860     gue punya teman dibela-belain pinjem duwit kan...\n",
       "Name: tweet, Length: 3520, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
    "X_test_bow = vectorizer_bow.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4810)\t1\n",
      "  (0, 1147)\t1\n",
      "  (0, 10739)\t1\n",
      "  (0, 9318)\t1\n",
      "  (0, 9102)\t1\n",
      "  (0, 10019)\t1\n",
      "  (0, 10380)\t1\n",
      "  (0, 10859)\t1\n",
      "  (0, 2700)\t1\n",
      "  (0, 11153)\t1\n",
      "  (0, 346)\t1\n",
      "  (0, 349)\t1\n",
      "  (0, 7638)\t1\n",
      "  (0, 1087)\t2\n",
      "  (0, 4210)\t1\n",
      "  (0, 5970)\t1\n",
      "  (0, 11245)\t1\n",
      "  (0, 4273)\t1\n",
      "  (0, 11411)\t1\n",
      "  (0, 4271)\t1\n",
      "  (0, 9066)\t1\n",
      "  (0, 9605)\t1\n",
      "  (0, 253)\t1\n",
      "  (0, 3033)\t1\n",
      "  (1, 10821)\t1\n",
      "  :\t:\n",
      "  (3518, 2483)\t1\n",
      "  (3518, 3202)\t1\n",
      "  (3518, 10910)\t1\n",
      "  (3518, 299)\t1\n",
      "  (3518, 8549)\t1\n",
      "  (3518, 3138)\t1\n",
      "  (3518, 4641)\t1\n",
      "  (3519, 1504)\t1\n",
      "  (3519, 3607)\t1\n",
      "  (3519, 10605)\t1\n",
      "  (3519, 10805)\t1\n",
      "  (3519, 8681)\t1\n",
      "  (3519, 10477)\t1\n",
      "  (3519, 9321)\t1\n",
      "  (3519, 4914)\t1\n",
      "  (3519, 8358)\t2\n",
      "  (3519, 11337)\t1\n",
      "  (3519, 5188)\t1\n",
      "  (3519, 7640)\t1\n",
      "  (3519, 470)\t1\n",
      "  (3519, 7951)\t1\n",
      "  (3519, 3390)\t1\n",
      "  (3519, 2290)\t1\n",
      "  (3519, 1050)\t1\n",
      "  (3519, 2713)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3033)\t0.22954952181025595\n",
      "  (0, 253)\t0.1820641846385591\n",
      "  (0, 9605)\t0.2500003433823169\n",
      "  (0, 9066)\t0.23803737965372196\n",
      "  (0, 4271)\t0.2500003433823169\n",
      "  (0, 11411)\t0.1721368072098088\n",
      "  (0, 4273)\t0.22954952181025595\n",
      "  (0, 11245)\t0.1672891608802246\n",
      "  (0, 5970)\t0.10814039858178676\n",
      "  (0, 4210)\t0.17432331096844592\n",
      "  (0, 1087)\t0.35588121304178577\n",
      "  (0, 7638)\t0.2130384503539307\n",
      "  (0, 349)\t0.1721368072098088\n",
      "  (0, 346)\t0.2500003433823169\n",
      "  (0, 11153)\t0.2500003433823169\n",
      "  (0, 2700)\t0.14427112963688324\n",
      "  (0, 10859)\t0.13868767712190488\n",
      "  (0, 10380)\t0.1268379737967491\n",
      "  (0, 10019)\t0.1997029461808805\n",
      "  (0, 9102)\t0.20251500621062005\n",
      "  (0, 9318)\t0.12241984116408033\n",
      "  (0, 10739)\t0.18864787866613406\n",
      "  (0, 1147)\t0.18357755732589456\n",
      "  (0, 4810)\t0.17925212460881954\n",
      "  (1, 895)\t0.22239438583203394\n",
      "  :\t:\n",
      "  (3518, 1532)\t0.15131114175447472\n",
      "  (3518, 8554)\t0.2080624342218105\n",
      "  (3518, 5214)\t0.1677000294324275\n",
      "  (3518, 5428)\t0.15604174579959643\n",
      "  (3518, 495)\t0.12332068707344476\n",
      "  (3518, 1499)\t0.20312081639137167\n",
      "  (3518, 5010)\t0.14152874735076804\n",
      "  (3519, 2713)\t0.2621542090294831\n",
      "  (3519, 1050)\t0.2621542090294831\n",
      "  (3519, 2290)\t0.2621542090294831\n",
      "  (3519, 3390)\t0.22816461472660593\n",
      "  (3519, 7951)\t0.24070916267197498\n",
      "  (3519, 470)\t0.21236035339582315\n",
      "  (3519, 7640)\t0.249609661084114\n",
      "  (3519, 5188)\t0.249609661084114\n",
      "  (3519, 11337)\t0.23380539975333123\n",
      "  (3519, 8358)\t0.499219322168228\n",
      "  (3519, 4914)\t0.1718822864638018\n",
      "  (3519, 9321)\t0.187966537597177\n",
      "  (3519, 10477)\t0.23380539975333123\n",
      "  (3519, 8681)\t0.12259425128527934\n",
      "  (3519, 10805)\t0.1978190699569588\n",
      "  (3519, 10605)\t0.12878385180301702\n",
      "  (3519, 3607)\t0.09925356756853812\n",
      "  (3519, 1504)\t0.10047659882865577\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-grams (Unigram and Bigram)\n",
    "vectorizer_ngram = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_ngram = vectorizer_ngram.fit_transform(X_train)\n",
    "X_test_ngram = vectorizer_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27918)\t1\n",
      "  (0, 8289)\t1\n",
      "  (0, 64020)\t1\n",
      "  (0, 54790)\t1\n",
      "  (0, 52951)\t1\n",
      "  (0, 59578)\t1\n",
      "  (0, 61327)\t1\n",
      "  (0, 64775)\t1\n",
      "  (0, 16602)\t1\n",
      "  (0, 66347)\t1\n",
      "  (0, 2330)\t1\n",
      "  (0, 2338)\t1\n",
      "  (0, 45157)\t1\n",
      "  (0, 7900)\t2\n",
      "  (0, 24271)\t1\n",
      "  (0, 35879)\t1\n",
      "  (0, 66768)\t1\n",
      "  (0, 24631)\t1\n",
      "  (0, 67551)\t1\n",
      "  (0, 24627)\t1\n",
      "  (0, 52845)\t1\n",
      "  (0, 57176)\t1\n",
      "  (0, 1787)\t1\n",
      "  (0, 18380)\t1\n",
      "  (0, 27922)\t1\n",
      "  :\t:\n",
      "  (3519, 20950)\t1\n",
      "  (3519, 31517)\t1\n",
      "  (3519, 45166)\t1\n",
      "  (3519, 45167)\t1\n",
      "  (3519, 3030)\t1\n",
      "  (3519, 47287)\t1\n",
      "  (3519, 19734)\t1\n",
      "  (3519, 14867)\t1\n",
      "  (3519, 7467)\t1\n",
      "  (3519, 16691)\t1\n",
      "  (3519, 63181)\t1\n",
      "  (3519, 14868)\t1\n",
      "  (3519, 7468)\t1\n",
      "  (3519, 49755)\t1\n",
      "  (3519, 16692)\t1\n",
      "  (3519, 29570)\t1\n",
      "  (3519, 10370)\t1\n",
      "  (3519, 64344)\t1\n",
      "  (3519, 49757)\t1\n",
      "  (3519, 67272)\t1\n",
      "  (3519, 19735)\t1\n",
      "  (3519, 3034)\t1\n",
      "  (3519, 31519)\t1\n",
      "  (3519, 47290)\t1\n",
      "  (3519, 62219)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with Bag of Words\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.71      0.79      0.74       229\n",
      "        fear       0.72      0.64      0.68       119\n",
      "       happy       0.73      0.62      0.67       214\n",
      "        love       0.74      0.73      0.73       119\n",
      "     sadness       0.53      0.58      0.56       200\n",
      "\n",
      "    accuracy                           0.67       881\n",
      "   macro avg       0.68      0.67      0.68       881\n",
      "weighted avg       0.68      0.67      0.67       881\n",
      "\n",
      "Naive Bayes with TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.61      0.84      0.71       229\n",
      "        fear       0.97      0.29      0.44       119\n",
      "       happy       0.71      0.62      0.66       214\n",
      "        love       0.87      0.40      0.55       119\n",
      "     sadness       0.44      0.65      0.53       200\n",
      "\n",
      "    accuracy                           0.61       881\n",
      "   macro avg       0.72      0.56      0.58       881\n",
      "weighted avg       0.68      0.61      0.60       881\n",
      "\n",
      "Naive Bayes with N-grams\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.66      0.81      0.73       229\n",
      "        fear       0.82      0.63      0.71       119\n",
      "       happy       0.70      0.62      0.66       214\n",
      "        love       0.78      0.68      0.73       119\n",
      "     sadness       0.56      0.60      0.58       200\n",
      "\n",
      "    accuracy                           0.67       881\n",
      "   macro avg       0.70      0.67      0.68       881\n",
      "weighted avg       0.68      0.67      0.67       881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Bag of Words\n",
    "nb.fit(X_train_bow, y_train)\n",
    "y_pred_bow_nb = nb.predict(X_test_bow)\n",
    "print(\"Naive Bayes with Bag of Words\")\n",
    "print(classification_report(y_test, y_pred_bow_nb))\n",
    "\n",
    "# TF-IDF\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_nb = nb.predict(X_test_tfidf)\n",
    "print(\"Naive Bayes with TF-IDF\")\n",
    "print(classification_report(y_test, y_pred_tfidf_nb))\n",
    "\n",
    "# N-grams\n",
    "nb.fit(X_train_ngram, y_train)\n",
    "y_pred_ngram_nb = nb.predict(X_test_ngram)\n",
    "print(\"Naive Bayes with N-grams\")\n",
    "print(classification_report(y_test, y_pred_ngram_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Bag of Words\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.54      0.74      0.62       229\n",
      "        fear       0.84      0.62      0.71       119\n",
      "       happy       0.69      0.61      0.65       214\n",
      "        love       0.66      0.79      0.72       119\n",
      "     sadness       0.54      0.40      0.46       200\n",
      "\n",
      "    accuracy                           0.62       881\n",
      "   macro avg       0.65      0.63      0.63       881\n",
      "weighted avg       0.63      0.62      0.62       881\n",
      "\n",
      "Random Forest with TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.54      0.76      0.63       229\n",
      "        fear       0.84      0.60      0.70       119\n",
      "       happy       0.69      0.56      0.62       214\n",
      "        love       0.68      0.81      0.74       119\n",
      "     sadness       0.52      0.41      0.45       200\n",
      "\n",
      "    accuracy                           0.62       881\n",
      "   macro avg       0.65      0.63      0.63       881\n",
      "weighted avg       0.63      0.62      0.61       881\n",
      "\n",
      "Random Forest with N-grams\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.51      0.83      0.64       229\n",
      "        fear       0.88      0.59      0.70       119\n",
      "       happy       0.71      0.54      0.62       214\n",
      "        love       0.72      0.80      0.76       119\n",
      "     sadness       0.53      0.35      0.42       200\n",
      "\n",
      "    accuracy                           0.62       881\n",
      "   macro avg       0.67      0.62      0.63       881\n",
      "weighted avg       0.64      0.62      0.61       881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Bag of Words\n",
    "rf.fit(X_train_bow, y_train)\n",
    "y_pred_bow_rf = rf.predict(X_test_bow)\n",
    "print(\"Random Forest with Bag of Words\")\n",
    "print(classification_report(y_test, y_pred_bow_rf))\n",
    "\n",
    "# TF-IDF\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_rf = rf.predict(X_test_tfidf)\n",
    "print(\"Random Forest with TF-IDF\")\n",
    "print(classification_report(y_test, y_pred_tfidf_rf))\n",
    "\n",
    "# N-grams\n",
    "rf.fit(X_train_ngram, y_train)\n",
    "y_pred_ngram_rf = rf.predict(X_test_ngram)\n",
    "print(\"Random Forest with N-grams\")\n",
    "print(classification_report(y_test, y_pred_ngram_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Bag of Words\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.58      0.77      0.67       229\n",
      "        fear       0.87      0.51      0.65       119\n",
      "       happy       0.62      0.63      0.62       214\n",
      "        love       0.75      0.72      0.74       119\n",
      "     sadness       0.50      0.43      0.46       200\n",
      "\n",
      "    accuracy                           0.62       881\n",
      "   macro avg       0.66      0.61      0.63       881\n",
      "weighted avg       0.63      0.62      0.62       881\n",
      "\n",
      "SVM with TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.62      0.81      0.70       229\n",
      "        fear       0.88      0.55      0.67       119\n",
      "       happy       0.66      0.65      0.66       214\n",
      "        love       0.79      0.70      0.74       119\n",
      "     sadness       0.53      0.51      0.52       200\n",
      "\n",
      "    accuracy                           0.65       881\n",
      "   macro avg       0.70      0.64      0.66       881\n",
      "weighted avg       0.67      0.65      0.65       881\n",
      "\n",
      "SVM with N-grams\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.59      0.75      0.66       229\n",
      "        fear       0.84      0.49      0.62       119\n",
      "       happy       0.59      0.64      0.61       214\n",
      "        love       0.75      0.76      0.75       119\n",
      "     sadness       0.50      0.42      0.46       200\n",
      "\n",
      "    accuracy                           0.61       881\n",
      "   macro avg       0.65      0.61      0.62       881\n",
      "weighted avg       0.63      0.61      0.61       881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm = SVC()\n",
    "\n",
    "# Bag of Words\n",
    "svm.fit(X_train_bow, y_train)\n",
    "y_pred_bow_svm = svm.predict(X_test_bow)\n",
    "print(\"SVM with Bag of Words\")\n",
    "print(classification_report(y_test, y_pred_bow_svm))\n",
    "\n",
    "# TF-IDF\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf_svm = svm.predict(X_test_tfidf)\n",
    "print(\"SVM with TF-IDF\")\n",
    "print(classification_report(y_test, y_pred_tfidf_svm))\n",
    "\n",
    "# N-grams\n",
    "svm.fit(X_train_ngram, y_train)\n",
    "y_pred_ngram_svm = svm.predict(X_test_ngram)\n",
    "print(\"SVM with N-grams\")\n",
    "print(classification_report(y_test, y_pred_ngram_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use three representation in one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB with Combined Features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.67      0.82      0.73       229\n",
      "        fear       0.80      0.62      0.70       119\n",
      "       happy       0.71      0.62      0.66       214\n",
      "        love       0.77      0.69      0.73       119\n",
      "     sadness       0.53      0.58      0.56       200\n",
      "\n",
      "    accuracy                           0.67       881\n",
      "   macro avg       0.70      0.66      0.68       881\n",
      "weighted avg       0.68      0.67      0.67       881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the feature extraction steps\n",
    "vectorizer_bow = CountVectorizer()\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "vectorizer_ngram = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Combine the features using FeatureUnion\n",
    "combined_features = FeatureUnion([\n",
    "    (\"bow\", vectorizer_bow),\n",
    "    (\"tfidf\", vectorizer_tfidf),\n",
    "    (\"ngram\", vectorizer_ngram)\n",
    "])\n",
    "\n",
    "# Create a pipeline that first transforms the data and then applies the model\n",
    "pipeline = Pipeline([\n",
    "    (\"features\", combined_features),\n",
    "    (\"classifier\", MultinomialNB())  # You can replace MultinomialNB with any other classifier\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"MultinomialNB with Combined Features\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Combined Features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.52      0.79      0.62       229\n",
      "        fear       0.86      0.63      0.73       119\n",
      "       happy       0.69      0.55      0.61       214\n",
      "        love       0.67      0.81      0.73       119\n",
      "     sadness       0.55      0.36      0.43       200\n",
      "\n",
      "    accuracy                           0.61       881\n",
      "   macro avg       0.66      0.63      0.63       881\n",
      "weighted avg       0.63      0.61      0.61       881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_rf = Pipeline([\n",
    "    (\"features\", combined_features),\n",
    "    (\"classifier\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = pipeline_rf.predict(X_test)\n",
    "print(\"Random Forest with Combined Features\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Combined Features\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.58      0.75      0.66       229\n",
      "        fear       0.86      0.50      0.63       119\n",
      "       happy       0.60      0.63      0.62       214\n",
      "        love       0.75      0.75      0.75       119\n",
      "     sadness       0.49      0.42      0.45       200\n",
      "\n",
      "    accuracy                           0.61       881\n",
      "   macro avg       0.65      0.61      0.62       881\n",
      "weighted avg       0.62      0.61      0.61       881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    (\"features\", combined_features),\n",
    "    (\"classifier\", SVC())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_svm = pipeline_svm.predict(X_test)\n",
    "print(\"SVM with Combined Features\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
